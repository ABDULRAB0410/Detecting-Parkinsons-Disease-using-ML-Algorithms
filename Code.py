# -*- coding: utf-8 -*-
"""Mini Project(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1d6KftBHa8V31-jE1fHGoe3af40DhD4eW

# **MACHINE LEARNING MINI-PROJECT**

# **Apply ML Algorthims on Parkinsons Disease Dataset**


"""

import numpy as np

from sklearn.preprocessing import LabelEncoder

import seaborn as sns

import matplotlib.pyplot as plt

from sklearn import metrics

import pandas as pd
df=pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data")
df.head()

df.shape

"""# **Exploratory** **Data** **Analysis**"""

df.isnull().sum()

df.describe()

df.columns

"""# Data Visualizaton"""

plt.figure(figsize=(10,6))
df.status.hist() #status coloumn
plt.xlabel('status')
plt.ylabel('Frequencies')
plt.plot()

plt.figure(figsize = (10,6))
sns.barplot(x = 'status' , y = 'NHR', data =df)

"""The persons suffering wit Parkinsons disease are having high values of NHR in comparison to healthy people"""

plt.figure(figsize = (10,6))
sns.barplot(x = 'status' , y = 'HNR', data =df)

"""Healthy persons are having high HNR in comparison to Parkinsons disease affected persons"""

rows = 3
cols = 7
fig, ax = plt.subplots(nrows=rows, ncols = cols, figsize = (16, 4))
col = df.columns
index = 1
for i in range(rows) :
  for j in range(cols) :
    sns.distplot(df[col[index]],ax = ax[i][j])
    index += 1
    plt.tight_layout()

from matplotlib import axis

df.drop(['name'], axis=1, inplace = True)

df.head(5)

x=df.drop(labels = ['status'], axis = 1)

y = df['status']

x.head()

y.head()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.2, random_state = 40)

x_train.shape

x_test.shape

"""# **Logistic Regression** by Ch. Prudhvi"""

from sklearn.linear_model import LogisticRegression

log_reg = LogisticRegression().fit(x_train, y_train)

train_pred = log_reg.predict(x_train)

train_pred

test_pred = log_reg.predict(x_test)

test_pred

from sklearn.metrics import accuracy_score, confusion_matrix

accuracy_score(y_train, train_pred)   #Training Accuracy

accuracy_score(y_test, test_pred)  #Test Accuracy

confusion_matrix(y_test, test_pred)

print("Training Accuracy using logistic regression is:", accuracy_score(y_train, train_pred))
print("Testing Accuracy using logistic regression is:", accuracy_score(y_test, test_pred))

"""# **Decision Tree**  By Akash Shreejay"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier().fit(x_train, y_train)

train_pred_dt = dt.predict(x_train)

train_pred_dt

test_pred_dt = dt.predict(x_test)

test_pred_dt

print("Training Accuracy using Decision tree is:", accuracy_score(y_train, train_pred_dt))
print("Testing Accuracy using Decision tree is:", accuracy_score(y_test, test_pred_dt))

confusion_matrix(y_train, train_pred_dt)

confusion_matrix(y_test, test_pred_dt)

"""# **Random Forest Algorthim** By Abdul Rab Badruddin"""

from sklearn.ensemble import RandomForestClassifier

rf= RandomForestClassifier(n_estimators=30, max_depth=10, random_state=1)

rf = RandomForestClassifier().fit(x_train, y_train)

train_pred_rf = rf.predict(x_train)

train_pred_rf

test_pred_rf = rf.predict(x_test)

test_pred_rf

print("Training Accuracy using Random Forest is:", accuracy_score(y_train, train_pred_rf))
print("Testing Accuracy using Random Forest is:", accuracy_score(y_test, test_pred_rf))

confusion_matrix(y_test, test_pred_rf)

"""# **K-Nearest Neighbour Algorithm** By G.Akshita"""

from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier(n_neighbors= 3).fit(x_train, y_train)

train_pred_kn = kn.predict(x_train)

train_pred_kn

test_pred_kn = kn.predict(x_test)

test_pred_kn

print("Training Accuracy using K-Nearest Neighbors is:", accuracy_score(y_train, train_pred_kn))
print("Testing Accuracy using K-Nearest Neighbors is:", accuracy_score(y_test, test_pred_kn))

confusion_matrix(y_test, test_pred_kn)



"""So, according to classification of this dataset by different algorithms , we can say that Random Forest has the most correct accuracy as training[1.0] and test [92%]"""